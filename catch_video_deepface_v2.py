import cv2
import json
import os
import numpy as np
from deepface import DeepFace
import time
from numpy import dot
from numpy.linalg import norm

# =========================
# é…ç½®
# =========================
address = "udp://localhost:5000"
db_json_path = "./photo_database.json"
MODEL_NAME = "VGG-Face"
SIM_THRESHOLD = 0   # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¯è‡ªå·±è°ƒ

# =========================
# å·¥å…·å‡½æ•°
# =========================
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


# =========================
# Step1: è¯»å– JSONï¼Œæ„å»ºæ•°æ®åº“ embedding
# =========================
print("Loading face database from JSON...")

with open(db_json_path, "r", encoding="utf-8") as f:
    db = json.load(f)

# ç»“æ„ï¼š
# {
#   "ç§‘æ¯”Â·å¸ƒè±æ©ç‰¹": [emb1, emb2, ...],
#   "æŸæŸ": [...]
# }
print(f'Database:\n {db}')

db_embeddings = {}

for person_name, img_paths in db.items():
    db_embeddings[person_name] = []
    for img_path in img_paths:
        try:
            emb = DeepFace.represent(
                img_path=img_path,
                model_name=MODEL_NAME,
                enforce_detection=False
            )[0]["embedding"]
            db_embeddings[person_name].append(emb)
        except Exception as e:
            print(f"[Skip] {img_path}: {e}")

print(f"Database loaded: {len(db_embeddings)} persons")

# =========================
# Step2: å‘½ä»¤å¾ªç¯ï¼ˆC / Qï¼‰
# =========================
print("\nCommand:")
print("  C - Capture & recognize")
print("  Q - Quit")

while True:
    cmd = input("\nEnter command (C/Q): ").strip().upper()

    if cmd == "Q":
        print("Bye ğŸ‘‹")
        break

    if cmd != "C":
        print("Invalid command.")
        continue

    # =========================
    # Step3: æ‰“å¼€æ‘„åƒå¤´ï¼Œé‡‡é›†ä¸€å¸§
    # =========================
    # cap = cv2.VideoCapture(address)
    # if not cap.isOpened():
    #     print("Error: Cannot open camera")
    #     continue

    # frame = None
    # ret = False

    # # ç»™ç½‘ç»œæµä¸€ç‚¹ç¼“å†²æ—¶é—´
    # time.sleep(0.5)

    # for _ in range(20):  # æœ€å¤šå°è¯• 20 æ¬¡
    #     ret, frame = cap.read()
    #     if ret and frame is not None:
    #         break
    #     time.sleep(0.05)

    # cap.release()

    # if not ret or frame is None:
    #     print("Failed to capture frame (no data from stream)")
    #     continue


    temp_img_path = "temp_frame.jpg"
    # cv2.imwrite(temp_img_path, frame)

    # =========================
    # Step4: æå–å½“å‰äººè„¸ embedding
    # =========================
    try:
        face_emb = DeepFace.represent(
            img_path=temp_img_path,
            model_name=MODEL_NAME,
            enforce_detection=False
        )[0]["embedding"]
    except Exception:
        print("No face detected")
        continue

    # =========================
    # Step5: ä¸æ•°æ®åº“æ¯”å¯¹
    # =========================
    best_person = None
    best_score = -1
    
    for person_name, emb_list in db_embeddings.items():
        for emb in emb_list:
            sim = dot(face_emb, emb) / (norm(face_emb) * norm(emb))
            if sim > best_score:
                best_score = sim
                best_person = person_name

    # =========================
    # Step6: è¾“å‡ºç»“æœ
    # =========================
    if best_person is not None and best_score > SIM_THRESHOLD:
        print(f"ä½ å¥½ï¼{best_person}")
        print(f"confidence: {best_score:.4f}")
    else:
        print("æœªè¯†åˆ«åˆ°å·²çŸ¥èº«ä»½")

    # å¯é€‰ï¼šæ˜¾ç¤ºé‡‡é›†ç”»é¢
    # cv2.imshow("Captured Frame", frame)
    # cv2.waitKey(1000)
    # cv2.destroyAllWindows()
